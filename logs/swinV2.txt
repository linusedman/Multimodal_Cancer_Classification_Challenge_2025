model.swinv2.encoder.layers.0.blocks.1.attention.self.key.weight : requires_grad=    0 (9216 params)
model.swinv2.encoder.layers.0.blocks.1.attention.self.value.weight : requires_grad=    0 (9216 params)
model.swinv2.encoder.layers.0.blocks.1.attention.self.value.bias : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.1.attention.output.dense.weight : requires_grad=    0 (9216 params)
model.swinv2.encoder.layers.0.blocks.1.attention.output.dense.bias : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.1.layernorm_before.weight : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.1.layernorm_before.bias : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.1.intermediate.dense.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.0.blocks.1.intermediate.dense.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.0.blocks.1.output.dense.weight   : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.0.blocks.1.output.dense.bias     : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.1.layernorm_after.weight : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.1.layernorm_after.bias  : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.downsample.reduction.weight    : requires_grad=    0 (73728 params)
model.swinv2.encoder.layers.0.downsample.norm.weight         : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.0.downsample.norm.bias           : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.logit_scale : requires_grad=    0 (6 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (3072 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.query.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.query.bias : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.key.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.value.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.value.bias : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.0.attention.output.dense.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.1.blocks.0.attention.output.dense.bias : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.0.layernorm_before.weight : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.0.layernorm_before.bias : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.0.intermediate.dense.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.1.blocks.0.intermediate.dense.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.1.blocks.0.output.dense.weight   : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.1.blocks.0.output.dense.bias     : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.0.layernorm_after.weight : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.0.layernorm_after.bias  : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.logit_scale : requires_grad=    0 (6 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (3072 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.query.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.query.bias : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.key.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.value.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.value.bias : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.1.attention.output.dense.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.1.blocks.1.attention.output.dense.bias : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.1.layernorm_before.weight : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.1.layernorm_before.bias : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.1.intermediate.dense.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.1.blocks.1.intermediate.dense.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.1.blocks.1.output.dense.weight   : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.1.blocks.1.output.dense.bias     : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.1.layernorm_after.weight : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.1.layernorm_after.bias  : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.downsample.reduction.weight    : requires_grad=    0 (294912 params)
model.swinv2.encoder.layers.1.downsample.norm.weight         : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.1.downsample.norm.bias           : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.logit_scale : requires_grad=    0 (12 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (6144 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.query.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.query.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.key.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.value.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.value.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.0.attention.output.dense.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.0.attention.output.dense.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.0.layernorm_before.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.0.layernorm_before.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.0.intermediate.dense.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.0.intermediate.dense.bias : requires_grad=    0 (1536 params)
model.swinv2.encoder.layers.2.blocks.0.output.dense.weight   : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.0.output.dense.bias     : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.0.layernorm_after.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.0.layernorm_after.bias  : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.logit_scale : requires_grad=    0 (12 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (6144 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.query.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.query.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.key.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.value.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.value.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.1.attention.output.dense.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.1.attention.output.dense.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.1.layernorm_before.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.1.layernorm_before.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.1.intermediate.dense.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.1.intermediate.dense.bias : requires_grad=    0 (1536 params)
model.swinv2.encoder.layers.2.blocks.1.output.dense.weight   : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.1.output.dense.bias     : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.1.layernorm_after.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.1.layernorm_after.bias  : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.logit_scale : requires_grad=    0 (12 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (6144 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.query.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.query.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.key.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.value.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.value.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.2.attention.output.dense.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.2.attention.output.dense.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.2.layernorm_before.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.2.layernorm_before.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.2.intermediate.dense.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.2.intermediate.dense.bias : requires_grad=    0 (1536 params)
model.swinv2.encoder.layers.2.blocks.2.output.dense.weight   : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.2.output.dense.bias     : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.2.layernorm_after.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.2.layernorm_after.bias  : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.logit_scale : requires_grad=    0 (12 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (6144 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.query.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.query.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.key.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.value.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.value.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.3.attention.output.dense.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.3.attention.output.dense.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.3.layernorm_before.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.3.layernorm_before.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.3.intermediate.dense.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.3.intermediate.dense.bias : requires_grad=    0 (1536 params)
model.swinv2.encoder.layers.2.blocks.3.output.dense.weight   : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.3.output.dense.bias     : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.3.layernorm_after.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.3.layernorm_after.bias  : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.logit_scale : requires_grad=    0 (12 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (6144 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.query.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.query.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.key.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.value.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.value.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.4.attention.output.dense.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.4.attention.output.dense.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.4.layernorm_before.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.4.layernorm_before.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.4.intermediate.dense.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.4.intermediate.dense.bias : requires_grad=    0 (1536 params)
model.swinv2.encoder.layers.2.blocks.4.output.dense.weight   : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.4.output.dense.bias     : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.4.layernorm_after.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.4.layernorm_after.bias  : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.logit_scale : requires_grad=    0 (12 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (6144 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.query.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.query.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.key.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.value.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.value.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.5.attention.output.dense.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.5.attention.output.dense.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.5.layernorm_before.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.5.layernorm_before.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.5.intermediate.dense.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.5.intermediate.dense.bias : requires_grad=    0 (1536 params)
model.swinv2.encoder.layers.2.blocks.5.output.dense.weight   : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.5.output.dense.bias     : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.5.layernorm_after.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.5.layernorm_after.bias  : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.downsample.reduction.weight    : requires_grad=    0 (1179648 params)
model.swinv2.encoder.layers.2.downsample.norm.weight         : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.2.downsample.norm.bias           : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.logit_scale : requires_grad=    0 (24 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (12288 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.query.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.query.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.key.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.value.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.value.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.0.attention.output.dense.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.3.blocks.0.attention.output.dense.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.0.layernorm_before.weight : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.0.layernorm_before.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.0.intermediate.dense.weight : requires_grad=    0 (2359296 params)
model.swinv2.encoder.layers.3.blocks.0.intermediate.dense.bias : requires_grad=    0 (3072 params)
model.swinv2.encoder.layers.3.blocks.0.output.dense.weight   : requires_grad=    0 (2359296 params)
model.swinv2.encoder.layers.3.blocks.0.output.dense.bias     : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.0.layernorm_after.weight : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.0.layernorm_after.bias  : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.logit_scale : requires_grad=    0 (24 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (12288 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.query.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.query.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.key.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.value.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.value.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.1.attention.output.dense.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.3.blocks.1.attention.output.dense.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.1.layernorm_before.weight : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.1.layernorm_before.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.1.intermediate.dense.weight : requires_grad=    0 (2359296 params)
model.swinv2.encoder.layers.3.blocks.1.intermediate.dense.bias : requires_grad=    0 (3072 params)
model.swinv2.encoder.layers.3.blocks.1.output.dense.weight   : requires_grad=    0 (2359296 params)
model.swinv2.encoder.layers.3.blocks.1.output.dense.bias     : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.1.layernorm_after.weight : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.1.layernorm_after.bias  : requires_grad=    0 (768 params)
model.swinv2.layernorm.weight                                : requires_grad=    0 (768 params)
model.swinv2.layernorm.bias                                  : requires_grad=    0 (768 params)
model.classifier.weight                                      : requires_grad=    1 (1536 params)
model.classifier.bias                                        : requires_grad=    1 (2 params)
========================================
Total parameters        : 27579692
Trainable parameters    : 1538
Frozen parameters       : 27578154
========================================
Checkpoint does not exist
model.safetensors: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 113M/113M [00:01<00:00, 100MB/s]
/home/user/swallace/miniconda3/envs/diffusion-ContourDiff/lib/python3.10/site-packages/transformers/image_processing_utils.py:44: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'
  return self.preprocess(images, **kwargs)
  ^Apoch 1:   1%|▋                                                                                                                        | 39/6430 [00:47<2:50:02,  1.60s/it^Apoch 1:   1%|▊                                                                                                                        | 43/6430 [00:49<1:25:36,  1.24it/s]
Epoch 1:   1%|▊                                                                                                                        | 45/6430 [00:52<2:20:26,  1.32s/itEpoch 1:   1%|▊                                                                                                                        | 46/6430 [00:53<2:05:57,  1.18s/itEpoch 1:   1%|▉                                                                                                                        | 47/6430 [00:54<1:49:08,  1.03s/itEpoch 1:   1%|▉                                                                                                                        | 48/6430 [00:54<1:30:37,  1.17it/sEpoch 1:   1%|▉                                                                                                                        | 49/6430 [00:55<1:18:44,  1.35it/sEpoch 1:   1%|▉                                                                                                                        | 50/6430 [00:55<1:12:18,  1.47it/sEpoch 1:   1%|▉                                                                       ^A                                               | 51/6430 [00:56<1:13:09,  1.45it/sEpoch 1:   1%|▉                                                                                                                        | 52/6430 [00:58<2:13:45,  1.26s/itEpoch 1:   1%|▉                                                                      Epoch 1:   1%|▉                                                                                                                        | 53/6430 [01:00<2:01:10,  1.14s/it]
Traceback (most recent call last):
  File "/home/user/swallace/miniconda3/envs/diffusion-ContourDiff/lib/python3.10/site-packages/transformers/feature_extraction_utils.py", line 192, in convert_to_tensors
    tensor = as_tensor(value)
  File "/home/user/swallace/miniconda3/envs/diffusion-ContourDiff/lib/python3.10/site-packages/transformers/feature_extraction_utils.py", line 141, in as_tensor
    value = np.array(value)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/srv/scratch1/swallace/CancerSeg/train.py", line 193, in <module>
    outputs = model(inputs)
  File "/home/user/swallace/miniconda3/envs/diffusion-ContourDiff/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/user/swallace/miniconda3/envs/diffusion-ContourDiff/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/srv/scratch1/swallace/CancerSeg/train.py", line 48, in forward
    inputs = self.processor(images=[transforms.ToPILImage()(img.cpu()) for img in x], return_tensors="pt", padding=True)
  File "/home/user/swallace/miniconda3/envs/diffusion-ContourDiff/lib/python3.10/site-packages/transformers/image_processing_utils.py", line 44, in __call__
    return self.preprocess(images, **kwargs)
  File "/home/user/swallace/miniconda3/envs/diffusion-ContourDiff/lib/python3.10/site-packages/transformers/utils/generic.py", line 870, in wrapper
    return func(*args, **valid_kwargs)
  File "/home/user/swallace/miniconda3/envs/diffusion-ContourDiff/lib/python3.10/site-packages/transformers/models/vit/image_processing_vit.py", line 285, in preprocess
    return BatchFeature(data=data, tensor_type=return_tensors)
  File "/home/user/swallace/miniconda3/envs/diffusion-ContourDiff/lib/python3.10/site-packages/transformers/feature_extraction_utils.py", line 78, in __init__
    self.convert_to_tensors(tensor_type=tensor_type)
  File "/home/user/swallace/miniconda3/envs/diffusion-ContourDiff/lib/python3.10/site-packages/transformers/feature_extraction_utils.py", line 198, in convert_to_tensors
    raise ValueError(
ValueError: Unable to create tensor, you should probably activate padding with 'padding=True' to have batched tensors with the same length.
 swallace@rolf   master ✚ ● ?  /srv/scratch1/swallace/CancerSeg 
▶ screen -ls
There are screens on:
	3223148.test	(05/27/2025 09:32:36 PM)	(Detached)
	3623734.SWIN	(05/26/2025 11:25:15 AM)	(Attached)
2 Sockets in /run/screen/S-swallace.
 swallace@rolf   master ✚ ● ?  /srv/scratch1/swallace/CancerSeg 
▶ screen -r SWIN
There is a screen on:
	3623734.SWIN	(05/26/2025 11:25:15 AM)	(Attached)
There is no screen to be resumed matching SWIN.
 swallace@rolf   master ✚ ● ?  /srv/scratch1/swallace/CancerSeg  ↵ 1 
▶ ./run.sh train.py
[22:59:20] Checking for free GPU...
Using GPU 6
Using dataset data/BF_dataset
We have 2 classes
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Some weights of Swinv2ForImageClassification were not initialized from the model checkpoint at microsoft/swinv2-tiny-patch4-window16-256 and are newly initialized because the shapes did not match:
- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated
- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
=== Parameter status (requires_grad) ===
model.swinv2.embeddings.patch_embeddings.projection.weight   : requires_grad=    0 (4608 params)
model.swinv2.embeddings.patch_embeddings.projection.bias     : requires_grad=    0 (96 params)
model.swinv2.embeddings.norm.weight                          : requires_grad=    0 (96 params)
model.swinv2.embeddings.norm.bias                            : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.0.attention.self.logit_scale : requires_grad=    0 (3 params)
model.swinv2.encoder.layers.0.blocks.0.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.0.blocks.0.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.0.blocks.0.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (1536 params)
model.swinv2.encoder.layers.0.blocks.0.attention.self.query.weight : requires_grad=    0 (9216 params)
model.swinv2.encoder.layers.0.blocks.0.attention.self.query.bias : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.0.attention.self.key.weight : requires_grad=    0 (9216 params)
model.swinv2.encoder.layers.0.blocks.0.attention.self.value.weight : requires_grad=    0 (9216 params)
model.swinv2.encoder.layers.0.blocks.0.attention.self.value.bias : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.0.attention.output.dense.weight : requires_grad=    0 (9216 params)
model.swinv2.encoder.layers.0.blocks.0.attention.output.dense.bias : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.0.layernorm_before.weight : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.0.layernorm_before.bias : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.0.intermediate.dense.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.0.blocks.0.intermediate.dense.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.0.blocks.0.output.dense.weight   : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.0.blocks.0.output.dense.bias     : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.0.layernorm_after.weight : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.0.layernorm_after.bias  : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.1.attention.self.logit_scale : requires_grad=    0 (3 params)
model.swinv2.encoder.layers.0.blocks.1.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.0.blocks.1.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.0.blocks.1.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (1536 params)
model.swinv2.encoder.layers.0.blocks.1.attention.self.query.weight : requires_grad=    0 (9216 params)
model.swinv2.encoder.layers.0.blocks.1.attention.self.query.bias : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.1.attention.self.key.weight : requires_grad=    0 (9216 params)
model.swinv2.encoder.layers.0.blocks.1.attention.self.value.weight : requires_grad=    0 (9216 params)
model.swinv2.encoder.layers.0.blocks.1.attention.self.value.bias : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.1.attention.output.dense.weight : requires_grad=    0 (9216 params)
model.swinv2.encoder.layers.0.blocks.1.attention.output.dense.bias : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.1.layernorm_before.weight : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.1.layernorm_before.bias : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.1.intermediate.dense.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.0.blocks.1.intermediate.dense.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.0.blocks.1.output.dense.weight   : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.0.blocks.1.output.dense.bias     : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.1.layernorm_after.weight : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.blocks.1.layernorm_after.bias  : requires_grad=    0 (96 params)
model.swinv2.encoder.layers.0.downsample.reduction.weight    : requires_grad=    0 (73728 params)
model.swinv2.encoder.layers.0.downsample.norm.weight         : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.0.downsample.norm.bias           : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.logit_scale : requires_grad=    0 (6 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (3072 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.query.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.query.bias : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.key.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.value.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.1.blocks.0.attention.self.value.bias : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.0.attention.output.dense.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.1.blocks.0.attention.output.dense.bias : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.0.layernorm_before.weight : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.0.layernorm_before.bias : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.0.intermediate.dense.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.1.blocks.0.intermediate.dense.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.1.blocks.0.output.dense.weight   : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.1.blocks.0.output.dense.bias     : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.0.layernorm_after.weight : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.0.layernorm_after.bias  : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.logit_scale : requires_grad=    0 (6 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (3072 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.query.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.query.bias : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.key.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.value.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.1.blocks.1.attention.self.value.bias : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.1.attention.output.dense.weight : requires_grad=    0 (36864 params)
model.swinv2.encoder.layers.1.blocks.1.attention.output.dense.bias : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.1.layernorm_before.weight : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.1.layernorm_before.bias : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.1.intermediate.dense.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.1.blocks.1.intermediate.dense.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.1.blocks.1.output.dense.weight   : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.1.blocks.1.output.dense.bias     : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.1.layernorm_after.weight : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.blocks.1.layernorm_after.bias  : requires_grad=    0 (192 params)
model.swinv2.encoder.layers.1.downsample.reduction.weight    : requires_grad=    0 (294912 params)
model.swinv2.encoder.layers.1.downsample.norm.weight         : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.1.downsample.norm.bias           : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.logit_scale : requires_grad=    0 (12 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (6144 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.query.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.query.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.key.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.value.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.0.attention.self.value.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.0.attention.output.dense.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.0.attention.output.dense.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.0.layernorm_before.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.0.layernorm_before.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.0.intermediate.dense.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.0.intermediate.dense.bias : requires_grad=    0 (1536 params)
model.swinv2.encoder.layers.2.blocks.0.output.dense.weight   : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.0.output.dense.bias     : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.0.layernorm_after.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.0.layernorm_after.bias  : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.logit_scale : requires_grad=    0 (12 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (6144 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.query.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.query.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.key.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.value.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.1.attention.self.value.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.1.attention.output.dense.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.1.attention.output.dense.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.1.layernorm_before.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.1.layernorm_before.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.1.intermediate.dense.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.1.intermediate.dense.bias : requires_grad=    0 (1536 params)
model.swinv2.encoder.layers.2.blocks.1.output.dense.weight   : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.1.output.dense.bias     : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.1.layernorm_after.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.1.layernorm_after.bias  : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.logit_scale : requires_grad=    0 (12 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (6144 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.query.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.query.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.key.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.value.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.2.attention.self.value.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.2.attention.output.dense.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.2.attention.output.dense.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.2.layernorm_before.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.2.layernorm_before.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.2.intermediate.dense.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.2.intermediate.dense.bias : requires_grad=    0 (1536 params)
model.swinv2.encoder.layers.2.blocks.2.output.dense.weight   : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.2.output.dense.bias     : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.2.layernorm_after.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.2.layernorm_after.bias  : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.logit_scale : requires_grad=    0 (12 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (6144 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.query.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.query.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.key.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.value.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.3.attention.self.value.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.3.attention.output.dense.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.3.attention.output.dense.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.3.layernorm_before.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.3.layernorm_before.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.3.intermediate.dense.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.3.intermediate.dense.bias : requires_grad=    0 (1536 params)
model.swinv2.encoder.layers.2.blocks.3.output.dense.weight   : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.3.output.dense.bias     : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.3.layernorm_after.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.3.layernorm_after.bias  : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.logit_scale : requires_grad=    0 (12 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (6144 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.query.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.query.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.key.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.value.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.4.attention.self.value.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.4.attention.output.dense.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.4.attention.output.dense.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.4.layernorm_before.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.4.layernorm_before.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.4.intermediate.dense.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.4.intermediate.dense.bias : requires_grad=    0 (1536 params)
model.swinv2.encoder.layers.2.blocks.4.output.dense.weight   : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.4.output.dense.bias     : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.4.layernorm_after.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.4.layernorm_after.bias  : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.logit_scale : requires_grad=    0 (12 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (6144 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.query.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.query.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.key.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.value.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.5.attention.self.value.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.5.attention.output.dense.weight : requires_grad=    0 (147456 params)
model.swinv2.encoder.layers.2.blocks.5.attention.output.dense.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.5.layernorm_before.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.5.layernorm_before.bias : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.5.intermediate.dense.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.5.intermediate.dense.bias : requires_grad=    0 (1536 params)
model.swinv2.encoder.layers.2.blocks.5.output.dense.weight   : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.2.blocks.5.output.dense.bias     : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.5.layernorm_after.weight : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.blocks.5.layernorm_after.bias  : requires_grad=    0 (384 params)
model.swinv2.encoder.layers.2.downsample.reduction.weight    : requires_grad=    0 (1179648 params)
model.swinv2.encoder.layers.2.downsample.norm.weight         : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.2.downsample.norm.bias           : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.logit_scale : requires_grad=    0 (24 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (12288 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.query.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.query.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.key.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.value.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.3.blocks.0.attention.self.value.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.0.attention.output.dense.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.3.blocks.0.attention.output.dense.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.0.layernorm_before.weight : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.0.layernorm_before.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.0.intermediate.dense.weight : requires_grad=    0 (2359296 params)
model.swinv2.encoder.layers.3.blocks.0.intermediate.dense.bias : requires_grad=    0 (3072 params)
model.swinv2.encoder.layers.3.blocks.0.output.dense.weight   : requires_grad=    0 (2359296 params)
model.swinv2.encoder.layers.3.blocks.0.output.dense.bias     : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.0.layernorm_after.weight : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.0.layernorm_after.bias  : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.logit_scale : requires_grad=    0 (24 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.continuous_position_bias_mlp.0.weight : requires_grad=    0 (1024 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.continuous_position_bias_mlp.0.bias : requires_grad=    0 (512 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.continuous_position_bias_mlp.2.weight : requires_grad=    0 (12288 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.query.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.query.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.key.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.value.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.3.blocks.1.attention.self.value.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.1.attention.output.dense.weight : requires_grad=    0 (589824 params)
model.swinv2.encoder.layers.3.blocks.1.attention.output.dense.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.1.layernorm_before.weight : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.1.layernorm_before.bias : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.1.intermediate.dense.weight : requires_grad=    0 (2359296 params)
model.swinv2.encoder.layers.3.blocks.1.intermediate.dense.bias : requires_grad=    0 (3072 params)
model.swinv2.encoder.layers.3.blocks.1.output.dense.weight   : requires_grad=    0 (2359296 params)
model.swinv2.encoder.layers.3.blocks.1.output.dense.bias     : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.1.layernorm_after.weight : requires_grad=    0 (768 params)
model.swinv2.encoder.layers.3.blocks.1.layernorm_after.bias  : requires_grad=    0 (768 params)
model.swinv2.layernorm.weight                                : requires_grad=    0 (768 params)
model.swinv2.layernorm.bias                                  : requires_grad=    0 (768 params)
model.classifier.weight                                      : requires_grad=    1 (1536 params)
model.classifier.bias                                        : requires_grad=    1 (2 params)
========================================
Total parameters        : 27579692
Trainable parameters    : 1538
Frozen parameters       : 27578154
========================================
Checkpoint does not exist
Epoch 1:   0%|                                             | 0/6430 [00:00<?, ?it/s]^A/home/user/swallace/miniconda3/envs/diffusion-ContourDiff/lib/python3.10/site-packages/transformers/image_processing_utils.py:44: UserWarning: The following named arguments are not valid for `ViTImageProcessor.preprocess` and were ignored: 'padding'
  return self.preprocess(images, **kwargs)
Epoch 1:   0%|                                   | 2/6430 [00:09<7:18:46,  4.10s/it]Epoch 1:   0%|                                   | 8/6430 [00:12<1:16:07,  1.41it/s]
